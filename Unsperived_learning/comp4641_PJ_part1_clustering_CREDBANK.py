# -*- coding: utf-8 -*-
"""COMP4641_PJ_PART1_CLUSTERING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nhHCJb2wSG-JeSbISPGFywQLpBT6Mz_f
"""

import numpy as np
import pandas as pd
import time
from sklearn.cluster import KMeans
from sklearn.cluster import MeanShift
from sklearn.metrics import silhouette_score
from sklearn import preprocessing
from matplotlib import pyplot as plt
from sklearn.cluster import DBSCAN
from datetime import datetime

import io
full_dataset = pd.read_csv("k_mean_word2vec_CREDBANK_1000v_2805.csv",error_bad_lines=False,engine='python')
full_dataset.columns = ['index','text','id','author_id','created_at','in_reply_to_status_id_str','in_reply_to_user_id_str','in_reply_to_screen_name','quoted_status_id_str','retweet_id','retweet_author_id','event','gp']

###############################################################
#reomve the time zone from str 
def removePDT (str):
  return str.remove('PDT')

###############################################################
#turn datatime into second
def to_integer(dt_time):
    return 10000*dt_time.year + 100*dt_time.month + dt_time.day
###############################################################
#(t1-t2)/24
#t1 = the time of each tweet
#t2 = the centriod time of each group
def cal_time_different(t1,t2):

  different = (t1-t2)
  different_min = different.total_seconds()/60

  
  if abs(different_min) >= (24*60):
    return 0
  else:
    return (different_min/(24*60))
###############################################################
def get_time_different_list(df,mean_list):
  diff_list=[]
  for i,row in df.iterrows():
    t2 = mean_list[row['gp']]
    t1 = row['time']
    diff_list.append(cal_time_different(t1,t2))

  return diff_list
  
###############################################################
def cal_time_average(df,no_cluster):
    mean_list = []
    print(df)
    for i in range(no_cluster):
        df1 = df.loc[df['gp'] == i]
        sum = 0
        for time in df1['time_stamp']:
          sum +=time
        timestamp = sum/len(df1) 
        print(len(df1))
        dt_object = datetime.fromtimestamp(timestamp)   
        mean_list.append(dt_object)
        print("group",i, dt_object)
    return mean_list
###############################################################
def cal_time_mode(df,no_cluster):
    mean_list = []
    print(df)
    for i in range(no_cluster):
        df1 = df.loc[df['gp'] == i]
        sum = 0
        for time in df1['time_stamp']:
          sum +=time
        timestamp = sum/len(df1) 
        print(len(df1))
        dt_object = datetime.fromtimestamp(timestamp)   
        mean_list.append(dt_object)
        print("group",i, dt_object)
    return mean_list

###############################################################
def to_timestamp(dt):
    dt = dt.timestamp()
    return dt

###############################################################
#turn str to datetime
def to_datetime(date_str):
  date_str = date_str.replace("PDT", "")
  return datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')


###############################################################
#df.drop([0, 1])
def try_to_datetime(df):
  error_time_index = []
  for index, row in df.iterrows():
    try:
      to_datetime(row['created_at'])
    except:
      error_time_index.append(index)
      continue
  print(error_time_index)
  df = df.drop(error_time_index)
  df['time'] = df['created_at'].apply(to_datetime)
  return df

print(full_dataset.loc[0,:])
print(len(full_dataset))

tweet_dataset = full_dataset 
#tweet_dataset['time'] = full_dataset['created_at'].apply(to_datetime)

tweet_dataset = try_to_datetime(tweet_dataset)
tweet_dataset['time_stamp'] = tweet_dataset['time'].apply(to_timestamp)
print(tweet_dataset.loc[0,:])

#find mean of each cluster
mean_list = cal_time_average(tweet_dataset,4)
print(mean_list)

#print(timestamp(datetime_object[1])-timestamp(datetime_object[303]))
#print((datetime_object[303]))
tweet_dataset['time_different'] = get_time_different_list(tweet_dataset,mean_list)

print(tweet_dataset['time_different'])
#print(cal_time_different(datetime_object[50],datetime_object[1]))
#print(cal_time_different(datetime_object[1],datetime_object[50]))

print(tweet_dataset.loc[0])

drop_dataset = tweet_dataset.drop(['index','time','text','id','author_id','created_at','in_reply_to_status_id_str','in_reply_to_user_id_str','in_reply_to_screen_name','quoted_status_id_str','retweet_id','retweet_author_id','event']
,axis=1)
print(drop_dataset.loc[0])

#normalization
x = drop_dataset.values #returns a numpy array
min_max_scaler = preprocessing.MinMaxScaler()
normalizsed_dataset_array = min_max_scaler.fit_transform(x)
nor_df = pd.DataFrame(normalizsed_dataset_array)

#print(tweet_dataset)
print(nor_df)

def WWS2(data):
  print('hi')
  Sum_of_squared_distances = []
  K = range(1,40)
  for k in K:
      km = KMeans(n_clusters=k)
      km = km.fit(data)
      Sum_of_squared_distances.append(km.inertia_)
  plt.plot(K, Sum_of_squared_distances, 'bx-')
  plt.xlabel('k')
  plt.ylabel('Sum_of_squared_distances')
  plt.title('Elbow Method For Optimal k')
  plt.show()

#WWS2(nor_df)

from sklearn import cluster
from sklearn import metrics
from sklearn.cluster import KMeans
print("START K-MEAN")
kmeans = cluster.KMeans(n_clusters=6)
start_time = time.time()
kmeans.fit(nor_df)
print("--- %s seconds ---" % (time.time() - start_time))
labels = kmeans.labels_

print ("Cluster id labels for inputted data")
print (labels)

 
#silhouette_score = metrics.silhouette_score(nor_df, labels, metric='euclidean')
 
#print ("Silhouette_score: ")
#print (silhouette_score)

tweet_dataset['part1_gp'] = labels
tweet_dataset.to_csv('k_mean_PART1_CREDBANK_2805.csv',index=False)

print("START CAL MEBERSHIP DEGREE")
df = tweet_dataset.groupby(['author_id']).agg({'part1_gp': np.size})
number_of_gp = tweet_dataset['part1_gp'].max() + 1
col_mame_list = ["total"]
for i in range(number_of_gp):
  df0 = tweet_dataset[(tweet_dataset['part1_gp']==i)].groupby(['author_id','part1_gp']).agg({'part1_gp': np.size})
  df = pd.merge(df, df0, on='author_id',how='left')
  col_mame_list.append('group_' + str(i))
df = df.fillna(0)

df.columns = col_mame_list
for i in range(number_of_gp):
  df['group_' + str(i)] = df['group_' + str(i)]/df['total']
df.head(10)
df.to_csv("membership_degree_2805.csv")


print("END")
