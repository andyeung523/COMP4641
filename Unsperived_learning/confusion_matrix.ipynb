{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "confusion_matrix.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfUlodxWL-TQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jirPiqUNT1yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_dataset = pd.read_csv('//content/drive/My Drive/Colab_Data/0306/50k1k/k_mean_PART1_CREDBANK_with_cred.csv')\n",
        "test_dataset = pd.read_csv('/content/drive/My Drive/Colab_Data/0306/test_dataset_with_avg_cred.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8If3HgqfVQnl",
        "colab_type": "code",
        "outputId": "9613be23-3908-4e5b-9b21-78fc7b3e8041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "full_dataset.loc[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text                         RT @EWNsport: The West Indies Cricket Board ha...\n",
              "id                                                                 5.23159e+17\n",
              "author_id                                                          3.28243e+07\n",
              "created_at                                                 2014-10-17 17:08:10\n",
              "in_reply_to_status_id_str                                                  NaN\n",
              "in_reply_to_user_id_str                                                    NaN\n",
              "in_reply_to_screen_name                                                    NaN\n",
              "quoted_status_id_str                                                      None\n",
              "retweet_id                                                  523137164859965440\n",
              "retweet_author_id                                                    242308246\n",
              "topic                                                       ebola,obama,#ebola\n",
              "topic_key                    ebola_obama_#ebola-20141016_181953-20141016_19...\n",
              "topic_terms                                    [u'ebola', u'obama', u'#ebola']\n",
              "Cred_Ratings                 ['1', '0', '2', '2', '2', '-2', '-2', '2', '2'...\n",
              "Reasons                      ['obama wants to intensify action against ebol...\n",
              "avg_cred                                                              0.666667\n",
              "gp                                                                           0\n",
              "time                                                       2014-10-17 17:08:10\n",
              "time_stamp                                                         1.41357e+09\n",
              "time_different                                                               0\n",
              "part1_gp                                                                     3\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehP4YbZaXQZ3",
        "colab_type": "code",
        "outputId": "0d64871e-5470-46b7-de67-c8029b2afe5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#turn text into vector vby word2vec\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import time\n",
        "import statistics as st\n",
        "\n",
        "from gensim import corpora\n",
        "from pprint import pprint\n",
        "from gensim.models import Word2Vec\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np \n",
        "import nltk \n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.cluster import KMeansClusterer    \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import PorterStemmer \n",
        "\n",
        "#########################################################################################################\n",
        "#vectorization of sentence \n",
        "def sent_vectorizer(sent):\n",
        "    sent_vec =[]\n",
        "    numw = 0\n",
        "    for w in sent:\n",
        "        try:\n",
        "            sent_vec.append(model[w])\n",
        "        except:\n",
        "            pass\n",
        "     \n",
        "    return sent_vec\n",
        "\n",
        "\n",
        "#########################################################################################################\n",
        "#lemmatization od sentence \n",
        "def lemmatization(text):\n",
        "    return [lemmatizer.lemmatize(w) for w in text]\n",
        "#########################################################################################################\n",
        "#stemming word  \n",
        "def stemmeriation(text):\n",
        "    return [ps.stem(w) for w in text]\n",
        "    \n",
        "\n",
        "#########################################################################################################\n",
        "#print each sentence \n",
        "def sent_print(sent):\n",
        "    print(sent)\n",
        "\n",
        "\n",
        "#text pre-processing\n",
        "not_words = ['!','@','?',',','.',\"'\", ')',';','(', '/',':','-','&','*','\"','\\'','\\\"','...','..','=]','=[','rt']\n",
        "\n",
        "tweet_dataset = full_dataset[['id','text']]\n",
        "tweet_dataset2 = test_dataset[['id','text']]\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "tweet_tokens = []\n",
        "for sent in tweet_dataset['text']:\n",
        "    tweet_tokens.append(tweet_tokenizer.tokenize(str(sent).lower()))\n",
        "tweet_dataset['tokenized_text'] = tweet_tokens\n",
        "\n",
        "tweet_tokens = []\n",
        "for sent in tweet_dataset2['text']:\n",
        "    tweet_tokens.append(tweet_tokenizer.tokenize(str(sent).lower()))  \n",
        "tweet_dataset2['tokenized_text'] = tweet_tokens\n",
        "\n",
        "tweet_dataset['tokenized_text'] = tweet_dataset['tokenized_text'].apply(lambda x: [item for item in x if item not in not_words])\n",
        "tweet_dataset2['tokenized_text'] = tweet_dataset2['tokenized_text'].apply(lambda x: [item for item in x if item not in not_words])\n",
        "\n",
        "for sentence in tweet_dataset['tokenized_text']: \n",
        "    num_to_del = 0\n",
        "    for word in sentence:\n",
        "        if '@' in word: \n",
        "            num_to_del +=1\n",
        "    for i in range(0,num_to_del):\n",
        "        for word in sentence:\n",
        "            if '@' in word: \n",
        "                sentence.remove(word)  \n",
        "                \n",
        "for sentence in tweet_dataset['tokenized_text']: \n",
        "    num_to_del = 0\n",
        "    for word in sentence:\n",
        "        if 'http' in word: \n",
        "            num_to_del +=1\n",
        "    for i in range(0,num_to_del):\n",
        "        for word in sentence:\n",
        "            if 'http' in word: \n",
        "                sentence.remove(word)\n",
        "\n",
        "#remove stop words\n",
        "stop_words = set(stopwords.words('english')) \n",
        "tweet_dataset['text_without_stop_word'] = tweet_dataset['tokenized_text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
        "tweet_dataset2['text_without_stop_word'] = tweet_dataset2['tokenized_text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
        "#stem\n",
        "ps = PorterStemmer() \n",
        "tweet_dataset['stemmed_text'] = tweet_dataset['text_without_stop_word'].apply(stemmeriation)\n",
        "tweet_dataset2['stemmed_text'] = tweet_dataset2['text_without_stop_word'].apply(stemmeriation)\n",
        "\n",
        "#lemma\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "tweet_dataset['lemmatized_text'] = tweet_dataset['stemmed_text'].apply(lemmatization)\n",
        "tweet_dataset2['lemmatized_text'] = tweet_dataset2['stemmed_text'].apply(lemmatization)\n",
        "\n",
        "\n",
        "#build word2vec model and run on each sentences \n",
        "model = Word2Vec(tweet_dataset['lemmatized_text'], min_count=1,size= 32) \n",
        "#tweet_dataset['vector_text'] = np.array([model[word] for word in (model.wv.vocab)])\n",
        "tweet_dataset['vector_text'] = tweet_dataset['lemmatized_text'].apply(sent_vectorizer)\n",
        "tweet_dataset2['vector_text'] = tweet_dataset2['lemmatized_text'].apply(sent_vectorizer)\n",
        "\n",
        "\n",
        "############################################################################################\n",
        "#get the avg vector of all vectors in a sentence \n",
        "def avg_vector(vect_list):\n",
        "  return np.mean(vect_list, axis=0)\n",
        "\n",
        "full_dataset['avg_vector_text'] = tweet_dataset['vector_text'].apply(avg_vector)\n",
        "test_dataset['avg_vector_text'] = tweet_dataset2['vector_text'].apply(avg_vector)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:74: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:99: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:103: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:107: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:114: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:115: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s-YXrgrq7vI",
        "colab_type": "code",
        "outputId": "6f366be8-4e9a-4616-f735-04e70b70c754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(full_dataset['part1_gp'].max())\n",
        "gp_no = full_dataset['part1_gp'].max() + 1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R25TXNzdVkCP",
        "colab_type": "code",
        "outputId": "dfa31a42-b36c-4124-9426-1cdff1eed1d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "#find the avg of each part_1 cluster\n",
        "cluster_avg_list= []\n",
        "\n",
        "for i in range(int(gp_no)):\n",
        "  cluster = {}\n",
        "  tmp_df = full_dataset.loc[full_dataset['part1_gp'] == i]\n",
        "  cluster['gp'] = i\n",
        "  cluster['avg_cred'] = tmp_df['avg_cred'].mean()\n",
        "  cluster['vector_text'] = np.mean(tmp_df['avg_vector_text'], axis=0)\n",
        "  cluster_avg_list.append(cluster)\n",
        "\n",
        "cluster_avg_list"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'avg_cred': 1.9160129410978173,\n",
              "  'gp': 0,\n",
              "  'vector_text': array([-0.6012176 ,  0.64073145, -0.97617966, -0.88037366, -0.42137703,\n",
              "         -0.26285276,  0.19215535,  0.90577567, -0.5461982 ,  0.2601638 ,\n",
              "         -0.1103292 , -0.5210664 , -0.19678713, -0.12484433, -0.34453493,\n",
              "          0.9413734 ,  0.89808565, -0.05933886, -2.2858796 , -0.00422704,\n",
              "         -1.3304263 ,  0.37016588,  0.8486145 ,  0.68812716,  1.231857  ,\n",
              "          0.71177226,  1.23936   , -0.50829715,  1.3695319 ,  1.6045274 ,\n",
              "          0.20028533, -0.6040871 ], dtype=float32)},\n",
              " {'avg_cred': 1.8779510418058025,\n",
              "  'gp': 1,\n",
              "  'vector_text': array([-9.4390798e-01,  6.9771343e-01, -1.4765527e-02, -1.2702520e+00,\n",
              "         -6.7228860e-01, -1.0491701e+00, -4.5218375e-02,  1.5507742e+00,\n",
              "         -5.0829154e-01, -4.5964932e-01, -3.8491210e-01, -4.8915648e-01,\n",
              "         -3.2647374e-01,  3.9432175e-02,  1.3395390e-01,  9.7279048e-01,\n",
              "          4.4802076e-01, -5.2327329e-01, -2.5036905e+00,  6.2208724e-01,\n",
              "         -1.7728586e-01,  8.4234379e-02,  3.9358518e-01,  4.0184441e-01,\n",
              "          2.4006230e-01,  4.7982249e-01,  8.8820374e-01, -2.2821703e-03,\n",
              "          1.3399322e+00,  4.3052095e-01,  1.4993039e-01, -7.0552891e-01],\n",
              "        dtype=float32)},\n",
              " {'avg_cred': 1.1136812969552607,\n",
              "  'gp': 2,\n",
              "  'vector_text': array([-0.37646556,  0.46250135, -0.73120236, -1.458333  , -0.46720836,\n",
              "         -0.19338085,  0.3277543 ,  1.357499  , -0.1996263 , -0.05236325,\n",
              "         -0.21256304, -0.41958767, -0.04126211,  0.1933717 , -0.4317636 ,\n",
              "          0.9440154 ,  0.93492985, -0.13433525, -2.2710245 ,  0.150289  ,\n",
              "         -0.7245832 ,  0.32696998,  0.72690177,  0.21285799,  1.3596637 ,\n",
              "          0.6465042 ,  0.919118  , -0.14891778,  0.9199874 ,  1.5687262 ,\n",
              "          0.0195231 , -0.5315935 ], dtype=float32)},\n",
              " {'avg_cred': 1.110094247797952,\n",
              "  'gp': 3,\n",
              "  'vector_text': array([-1.0369327 ,  0.76102704, -0.17720154, -0.88871896, -0.83277005,\n",
              "         -1.06701   , -0.19029552,  1.29928   , -0.64525527, -0.49929655,\n",
              "         -0.7071787 , -0.67593306, -0.45276263, -0.19956703,  0.3158913 ,\n",
              "          0.80900735,  0.11489643, -0.5207572 , -2.1788647 ,  0.2410781 ,\n",
              "         -0.56875247, -0.04428574,  0.32872748,  0.5765377 ,  0.31863818,\n",
              "          0.73124284,  0.7815285 ,  0.34962875,  1.3201258 ,  0.2579916 ,\n",
              "          0.3664194 , -0.59251434], dtype=float32)}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LjbPnT1Y4Hf",
        "colab_type": "code",
        "outputId": "ab1e2989-39ec-46f1-ffc8-05d82d8dbe92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "#find the cosin distace between the test_set and  avg of each cluster \n",
        "import numpy\n",
        "\n",
        "def get_shortest_cluster(tweet):\n",
        "  distance_list = []\n",
        "  for cluster in cluster_avg_list:\n",
        "    cosine_similarity = numpy.dot(tweet.avg_vector_text, cluster['vector_text'])/(numpy.linalg.norm(tweet.avg_vector_text)* numpy.linalg.norm(cluster['vector_text']))\n",
        "    #time_different  = abs(tweet.time_stamp -cluster['time_stamp'] )\n",
        "    distance_list.append(cosine_similarity)\n",
        "    #print(time_different)\n",
        "#  print(distance_list)\n",
        "    try:\n",
        "      min_value = min(distance_list)\n",
        "    except:\n",
        "      print(distance_list)\n",
        "      return 0\n",
        "    \n",
        "  return distance_list.index((min_value))\n",
        "\n",
        "\n",
        "test_dataset['pred_gp'] = test_dataset.apply(get_shortest_cluster,axis=1)\n",
        "print(test_dataset['pred_gp'])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "       nan, nan, nan, nan, nan, nan]), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "       nan, nan, nan, nan, nan, nan])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in less\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0      3\n",
            "1      3\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "733    3\n",
            "734    3\n",
            "735    3\n",
            "736    0\n",
            "737    3\n",
            "Name: pred_gp, Length: 738, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmK_65E0vwZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#assgin the cred_class on the test dataset's original cred and pred's cred\n",
        "def get_cred_class(cred):\n",
        "  if cred > 1.5:\n",
        "    return 2\n",
        "  if cred > 1:\n",
        "    return 1\n",
        "  return 0\n",
        "  \n",
        "cluster_cred_list = []\n",
        "\n",
        "for cluster in cluster_avg_list:\n",
        "    cluster_cred_list.append(cluster['avg_cred'])\n",
        "\n",
        "def get_pred_cred_class(gp):\n",
        "  for i in range(len(cluster_cred_list)):\n",
        "    if gp == i:\n",
        "      return get_cred_class(cluster_cred_list[i])\n",
        "\n",
        "test_dataset['cred_class'] = test_dataset['avg_cred'].apply(get_cred_class)\n",
        "test_dataset['pred_cred_class'] = test_dataset['pred_gp'].apply(get_pred_cred_class)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtqXZaA3KigV",
        "colab_type": "code",
        "outputId": "3f192fa6-7b0c-4d9b-dfe3-42d93c09a74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_dataset['avg_cred'].min()\n",
        "#test_dataset['pred_cred_class']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiMG7YZ_zPgG",
        "colab_type": "code",
        "outputId": "8c54b8cc-2135-4846-e8a4-b314c6492dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "#confusion marix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(test_dataset['cred_class'],test_dataset['pred_cred_class'])\n",
        "sn.heatmap(cm, annot=True,cmap='Blues', fmt='g')\n",
        "plt.show()\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "print ('Accuracy Score :',accuracy_score(test_dataset['cred_class'], test_dataset['pred_cred_class'])) \n",
        "print ('Report : ')\n",
        "print (classification_report(test_dataset['cred_class'], test_dataset['pred_cred_class']) )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score : 0.5840108401084011\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        13\n",
            "           1       0.58      0.71      0.64       376\n",
            "           2       0.59      0.47      0.52       349\n",
            "\n",
            "    accuracy                           0.58       738\n",
            "   macro avg       0.39      0.39      0.39       738\n",
            "weighted avg       0.57      0.58      0.57       738\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}